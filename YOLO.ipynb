{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Training YOLO model in Google Colab**"
      ],
      "metadata": {
        "id": "y8uaFt1CAaU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verifying NVIDIA GPU availability"
      ],
      "metadata": {
        "id": "RMeht1mZBsd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "G6To0MeVBtmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_0c110fOiz"
      },
      "source": [
        "We'll upload the dataset directly through colab, split it into training and validation sets, and create the config file needed to train the YOLO model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z8O6z-wVcPEF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# unzipping to a custom data folder\n",
        "!unzip -q /content/data.zip -d /content/custom_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultralytics requires a particular folder structure to store training data for models. The root folder is named `data`. Inside, there are two main folders:\n",
        "\n",
        "* `Train`: These are the actual images used to train the model. In one epoch of training, every image in the train set is passed into the neural network. The training algorithm adjusts the network weights to fit the data in the images.\n",
        "\n",
        "* `Validation`: These images are used to check the model's performance at the end of each training epoch.\n",
        "\n",
        "In each of these folders is an `images` folder and a `labels` folder, which hold the image files and annotation files respectively.\n",
        "\n",
        "I wrote a [Python script](https://github.com/iamvenk00/Anti-Cheating-Mechanism/blob/main/train_val_split.py) `train_val_split.py` that will automatically create the required folder structure and randomly move `75%` of dataset to the `train` folder and `25%` to the `validation` folder. Run the following code block to download and execute the script."
      ],
      "metadata": {
        "id": "eoPjqW6AYebn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/train_val_split.py https://raw.githubusercontent.com/iamvenk00/Anti-Cheating-Mechanism/refs/heads/main/train_val_split.py\n",
        "\n",
        "!python train_val_split.py --datapath=\"/content/custom_data\" --train_pct=0.75"
      ],
      "metadata": {
        "id": "8X62eFTugosf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installing Ultralytics"
      ],
      "metadata": {
        "id": "ZDhMP7YVCCD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "EMEDk5byzxY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run the code block below to automatically generate a `data.yaml` configuration file."
      ],
      "metadata": {
        "id": "0c5Kdh0GmQHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python function to automatically create data.yaml config file\n",
        "# 1. Reads \"classes.txt\" file to get list of class names\n",
        "# 2. Creates data dictionary with correct paths to folders, number of classes, and names of classes\n",
        "# 3. Writes data in YAML format to data.yaml\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "\n",
        "  # Read class.txt to get class names\n",
        "  if not os.path.exists(path_to_classes_txt):\n",
        "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
        "    return\n",
        "  with open(path_to_classes_txt, 'r') as f:\n",
        "    classes = []\n",
        "    for line in f.readlines():\n",
        "      if len(line.strip()) == 0: continue\n",
        "      classes.append(line.strip())\n",
        "  number_of_classes = len(classes)\n",
        "\n",
        "  # Create data dictionary\n",
        "  data = {\n",
        "      'path': '/content/data',\n",
        "      'train': 'train/images',\n",
        "      'val': 'validation/images',\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  # Write data to YAML file\n",
        "  with open(path_to_data_yaml, 'w') as f:\n",
        "    yaml.dump(data, f, sort_keys=False)\n",
        "  print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Define path to classes.txt and run function\n",
        "path_to_classes_txt = '/content/custom_data/classes.txt'\n",
        "path_to_data_yaml = '/content/data.yaml'\n",
        "\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "!cat /content/data.yaml"
      ],
      "metadata": {
        "id": "4letvP7X12ji",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several YOLO11 models sizes available to train, including `yolo11n.pt`, `yolo11s.pt`, `yolo11m.pt`, `yolo11l.pt`, and `yolo11xl.pt`. Larger models run slower but have higher accuracy, while smaller models run faster but have lower accuracy. If you aren't sure which model size to use, `yolo11s.pt` is a good starting point.\n",
        "\n",
        "You can also train YOLOv8 or YOLOv5 models by substituting `yolo11` for `yolov8` or `yolov5`.\n",
        "\n",
        "Setting the number of epochs dictates how long the model will train for. The best amount of epochs to use depends on the size of the dataset and the model architecture. If your dataset has less than 200 images, a good starting point is 60 epochs. If your dataset has more than 200 images, a good starting point is 40 epochs.\n",
        "\n",
        "Resolution has a large impact on the speed and accuracy of the model: a lower resolution model will have higher speed but less accuracy. YOLO models are typically trained and inferenced at a 640x640 resolution."
      ],
      "metadata": {
        "id": "DfKspYasCzC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run the following code block to begin training. If you want to use a different model, number of epochs or resolution, change `model`, `epochs`, `imgsz`."
      ],
      "metadata": {
        "id": "nQi_hXnUVPr-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bbpob1gTPlo"
      },
      "outputs": [],
      "source": [
        "!yolo detect train data=/content/data.yaml model=yolo11l.pt epochs=65 imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training algorithm will parse the images in the `training` and `validation` directories and then start training the model. At the end of each training epoch, the program runs the model on the validation dataset and reports the resulting mAP, precision and recall. As training continues, the mAP should generally increase with each epoch. Training will end once it goes through the number of epochs specified by `epochs`.\n",
        "\n",
        "The best trained model weights will be saved in `content/runs/detect/train/weights/best.pt`. Additional information about training is saved in the `content/runs/detect/train` folder, including a `results.png` file that shows how loss, precision, recall and mAP progressed over each epoch."
      ],
      "metadata": {
        "id": "vv0EYWJ5V6mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The model has been trained.\n",
        "\n",
        "The commands below run the model on the images in the validation folder and then display the results for the first 10 images."
      ],
      "metadata": {
        "id": "BX3PTrEPacGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PooP5Vjsg2Jn"
      },
      "outputs": [],
      "source": [
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=data/validation/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEEObQqoiGrs"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg')[:10]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model should draw a box around each object of interest in each image.\n",
        "\n",
        "You can also run the model on video files or other images images by uploading them to this notebook and using the above `!yolo detect predict` command, where `source` points to the location of the video file, image, or folder of images.\n",
        "\n",
        "The results will be saved in `runs/detect/predict`."
      ],
      "metadata": {
        "id": "EGiQw_gWbSBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the custom YOLO model\n",
        "\n",
        "Zip and download the trained model by running the code blocks below.\n",
        "\n",
        "The code creates a folder named `my_model`, moves the model weights into it, and renames them from `best.pt` to `my_model.pt`. It also adds the training results in case you want to refer to them later. It then zips the folder as `my_model.zip`."
      ],
      "metadata": {
        "id": "IcoBAeHXa86W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"my_model\" folder to store model weights and train results\n",
        "!mkdir /content/my_model\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/my_model/my_model.pt\n",
        "!cp -r /content/runs/detect/train /content/my_model\n",
        "\n",
        "# Zip into \"my_model.zip\"\n",
        "%cd my_model\n",
        "!zip /content/my_model.zip my_model.pt\n",
        "!zip -r /content/my_model.zip train\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "qcBdnOA9v85S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ypwonynLVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9c5c9a7-ac30-444a-dc1d-88d9a699df9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0662a6f3-1556-4ea3-a0f5-35d4844bd833\", \"my_model.zip\", 147739333)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Download. You can also download the model directly from the sidebar.\n",
        "from google.colab import files\n",
        "files.download('/content/my_model.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now, we'll run our downloaded model on a local device.\n",
        "\n",
        "I wrote a [Python script](https://github.com/iamvenk00/Anti-Cheating-Mechanism/blob/main/yolo_detect.py), `yolo_detect.py`, that shows how to load a model, run inference on an image source, parse the inference results and display boxes around each detected class in the image. The script gives an example of how to work with Ultralytics YOLO models in Python."
      ],
      "metadata": {
        "id": "YL06c6pb_UqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deploying on PC\n",
        "\n",
        "Install Ultralytics (which also installs import libraries like OpenCV-Python, Numpy, and PyTorch) by issuing the following command:\n",
        "```\n",
        "pip install ultralytics\n",
        "```\n",
        "\n",
        "If you have an NVIDIA GPU, you can install the GPU-enabled version of PyTorch by issuing the following command:\n",
        "```\n",
        "pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "```\n",
        "\n",
        "Extract downloaded model\n",
        "Take the `my_model.zip` file you downloaded and unzip it to a folder on your PC. In the terminal, move into the unzipped folder using:\n",
        "```\n",
        "cd path/to/folder\n",
        "```\n",
        "\n",
        "Download the `yolo_detect.py` script into the `my_model` folder using:\n",
        "```\n",
        "curl -o yolo_detect.py https://raw.githubusercontent.com/iamvenk00/Anti-Cheating-Mechanism/refs/heads/main/yolo_detect.py\n",
        "```\n",
        "\n",
        "We're now ready to run the script. To run inference, issue:\n",
        "```\n",
        "python yolo_detect.py --model my_model.pt --source usb0\n",
        "```\n",
        "\n",
        "A window will appear showing a live feed from your webcam with boxes drawn around detected objects in each frame.\n",
        "\n",
        "You can also run the model on an video file, image, or folder of images. To see a full list of arguments for `yolo_detect.py`, see the [file](https://github.com/iamvenk00/Anti-Cheating-Mechanism/blob/main/arguments.txt)."
      ],
      "metadata": {
        "id": "gzaJQ2sGEPhP"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}